"use strict";(globalThis.webpackChunkmcgrad_website=globalThis.webpackChunkmcgrad_website||[]).push([[638],{5530:(e,i,r)=>{r.r(i),r.d(i,{assets:()=>c,contentTitle:()=>o,default:()=>m,frontMatter:()=>s,metadata:()=>n,toc:()=>l});const n=JSON.parse('{"id":"api/metrics","title":"Metrics","description":"Metrics for evaluating calibration quality.","source":"@site/docs/api/metrics.md","sourceDirName":"api","slug":"/api/metrics","permalink":"/MCGrad/docs/api/metrics","draft":false,"unlisted":false,"editUrl":"https://github.com/facebookincubator/MCGrad/tree/main/website/docs/api/metrics.md","tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"sidebar_position":2},"sidebar":"tutorialSidebar","previous":{"title":"Methods","permalink":"/MCGrad/docs/api/methods"},"next":{"title":"Plotting","permalink":"/MCGrad/docs/api/plotting"}}');var t=r(4848),a=r(8453);const s={sidebar_position:2},o="Metrics",c={},l=[{value:"Calibration Metrics",id:"calibration-metrics",level:2},{value:"Expected Calibration Error (ECE)",id:"expected-calibration-error-ece",level:3},{value:"Multi-Calibration Metrics",id:"multi-calibration-metrics",level:2},{value:"Segment Calibration Error",id:"segment-calibration-error",level:3},{value:"Predictive Performance Metrics",id:"predictive-performance-metrics",level:2}];function d(e){const i={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,a.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(i.header,{children:(0,t.jsx)(i.h1,{id:"metrics",children:"Metrics"})}),"\n",(0,t.jsx)(i.p,{children:"Metrics for evaluating calibration quality."}),"\n",(0,t.jsxs)(i.admonition,{title:"Python API Documentation",type:"info",children:[(0,t.jsx)(i.p,{children:"For detailed Python API documentation with docstrings, refer to the source code or use Python's help:"}),(0,t.jsx)(i.pre,{children:(0,t.jsx)(i.code,{className:"language-python",children:"from multicalibration import metrics\nhelp(metrics)\n"})})]}),"\n",(0,t.jsx)(i.h2,{id:"calibration-metrics",children:"Calibration Metrics"}),"\n",(0,t.jsx)(i.h3,{id:"expected-calibration-error-ece",children:"Expected Calibration Error (ECE)"}),"\n",(0,t.jsx)(i.p,{children:"Measures the average difference between predicted probabilities and observed frequencies across bins."}),"\n",(0,t.jsx)(i.pre,{children:(0,t.jsx)(i.code,{className:"language-python",children:"from multicalibration.metrics import expected_calibration_error\n\nece = expected_calibration_error(\n    predictions=preds,\n    labels=labels,\n    n_bins=10\n)\n"})}),"\n",(0,t.jsx)(i.p,{children:"###Maximum Calibration Error (MCE)"}),"\n",(0,t.jsx)(i.p,{children:"Measures the maximum difference between predicted probabilities and observed frequencies."}),"\n",(0,t.jsx)(i.pre,{children:(0,t.jsx)(i.code,{className:"language-python",children:"from multicalibration.metrics import maximum_calibration_error\n\nmce = maximum_calibration_error(\n    predictions=preds,\n    labels=labels,\n    n_bins=10\n)\n"})}),"\n",(0,t.jsx)(i.h2,{id:"multi-calibration-metrics",children:"Multi-Calibration Metrics"}),"\n",(0,t.jsx)(i.h3,{id:"segment-calibration-error",children:"Segment Calibration Error"}),"\n",(0,t.jsx)(i.p,{children:"Evaluates calibration within specific segments."}),"\n",(0,t.jsx)(i.pre,{children:(0,t.jsx)(i.code,{className:"language-python",children:"from multicalibration.metrics import segment_calibration_error\n\nsegment_errors = segment_calibration_error(\n    predictions=preds,\n    labels=labels,\n    segments=segment_ids\n)\n"})}),"\n",(0,t.jsx)(i.h2,{id:"predictive-performance-metrics",children:"Predictive Performance Metrics"}),"\n",(0,t.jsx)(i.p,{children:"Standard ML metrics for comparing model performance:"}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.strong,{children:"Log Loss"})," - Negative log likelihood"]}),"\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.strong,{children:"Brier Score"})," - Mean squared difference between predictions and labels"]}),"\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.strong,{children:"PRAUC"})," - Precision-Recall Area Under Curve"]}),"\n"]}),"\n",(0,t.jsxs)(i.p,{children:["See the ",(0,t.jsx)(i.a,{href:"https://github.com/facebookincubator/MCGrad/blob/main/src/multicalibration/metrics.py",children:"source code"})," for full implementation details."]})]})}function m(e={}){const{wrapper:i}={...(0,a.R)(),...e.components};return i?(0,t.jsx)(i,{...e,children:(0,t.jsx)(d,{...e})}):d(e)}},8453:(e,i,r)=>{r.d(i,{R:()=>s,x:()=>o});var n=r(6540);const t={},a=n.createContext(t);function s(e){const i=n.useContext(a);return n.useMemo(function(){return"function"==typeof e?e(i):{...i,...e}},[i,e])}function o(e){let i;return i=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:s(e.components),n.createElement(a.Provider,{value:i},e.children)}}}]);